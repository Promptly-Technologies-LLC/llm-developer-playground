{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating the openai API's internal model list\n",
    "\n",
    "The documentation of the openai Python library could be better, so let's do an exploratory investigation to see what models are available through the API, and what data about the models we can retrieve programmatically. First we load the library and set our API key from a .env file in the project folder. \n",
    "\n",
    "Note that in order to use this notebook, you will need to copy the `sample.env` file as `.env`, and then copy and paste your valid API key into the file. Get your API key [here](https://platform.openai.com/account/api-keys). When uploading code to the Internet, make sure not to upload `.env`! Note that it is listed in `.gitignore` to prevent accidental sharing with git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries and set API key\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Available models\n",
    "\n",
    "We begin by calling the `list` method of the `Models` class from the openai library. This should give us a list of models we can call through the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'openai.openai_object.OpenAIObject'>\n"
     ]
    }
   ],
   "source": [
    "# Get models object from the openai API, and detect object type\n",
    "models = openai.Model.list()\n",
    "print(type(models))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigating the returned object, we find that it's a special OpenAI object type. The object behaves like a Python dictionary, though with a few additional methods for manipulating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['object', 'data'])\n"
     ]
    }
   ],
   "source": [
    "print(models.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object has two keys, 'object' and 'data'. The 'object' value tells us what object type is in the 'data' value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list\n"
     ]
    }
   ],
   "source": [
    "# Access 'object' value and verify that it's the same as the type of the 'data' value\n",
    "print(models['object'])\n",
    "assert models['object'] in str(type(models['data']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each list item corresponds to a model. Checking the length of the list reveals that there are many available models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "# Check length of models list\n",
    "print(len(models['data']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see what data is available for each model, we can examine one of the list items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Model model id=whisper-1 at 0x28262b0d010> JSON: {\n",
       "  \"created\": 1677532384,\n",
       "  \"id\": \"whisper-1\",\n",
       "  \"object\": \"model\",\n",
       "  \"owned_by\": \"openai-internal\",\n",
       "  \"parent\": null,\n",
       "  \"permission\": [\n",
       "    {\n",
       "      \"allow_create_engine\": false,\n",
       "      \"allow_fine_tuning\": false,\n",
       "      \"allow_logprobs\": true,\n",
       "      \"allow_sampling\": true,\n",
       "      \"allow_search_indices\": false,\n",
       "      \"allow_view\": true,\n",
       "      \"created\": 1683912666,\n",
       "      \"group\": null,\n",
       "      \"id\": \"modelperm-KlsZlfft3Gma8pI6A8rTnyjs\",\n",
       "      \"is_blocking\": false,\n",
       "      \"object\": \"model_permission\",\n",
       "      \"organization\": \"*\"\n",
       "    }\n",
       "  ],\n",
       "  \"root\": \"whisper-1\"\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['data'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"root\" key gives us the model name. For a complete list of model names, we can iterate through the list and print this \"root\" value for each list item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. whisper-1\n",
      "1. babbage\n",
      "2. gpt-3.5-turbo\n",
      "3. davinci\n",
      "4. text-davinci-edit-001\n",
      "5. text-davinci-003\n",
      "6. babbage-code-search-code\n",
      "7. text-similarity-babbage-001\n",
      "8. code-davinci-edit-001\n",
      "9. text-davinci-001\n",
      "10. ada\n",
      "11. babbage-code-search-text\n",
      "12. babbage-similarity\n",
      "13. code-search-babbage-text-001\n",
      "14. text-curie-001\n",
      "15. gpt-4\n",
      "16. code-search-babbage-code-001\n",
      "17. text-ada-001\n",
      "18. text-embedding-ada-002\n",
      "19. text-similarity-ada-001\n",
      "20. curie-instruct-beta\n",
      "21. gpt-4-0314\n",
      "22. ada-code-search-code\n",
      "23. ada-similarity\n",
      "24. code-search-ada-text-001\n",
      "25. text-search-ada-query-001\n",
      "26. davinci-search-document\n",
      "27. ada-code-search-text\n",
      "28. text-search-ada-doc-001\n",
      "29. davinci-instruct-beta\n",
      "30. text-similarity-curie-001\n",
      "31. code-search-ada-code-001\n",
      "32. ada-search-query\n",
      "33. text-search-davinci-query-001\n",
      "34. curie-search-query\n",
      "35. davinci-search-query\n",
      "36. babbage-search-document\n",
      "37. ada-search-document\n",
      "38. text-search-curie-query-001\n",
      "39. text-search-babbage-doc-001\n",
      "40. curie-search-document\n",
      "41. text-search-curie-doc-001\n",
      "42. babbage-search-query\n",
      "43. text-babbage-001\n",
      "44. text-search-davinci-doc-001\n",
      "45. text-search-babbage-query-001\n",
      "46. curie-similarity\n",
      "47. curie\n",
      "48. gpt-3.5-turbo-0301\n",
      "49. text-similarity-davinci-001\n",
      "50. text-davinci-002\n",
      "51. davinci-similarity\n",
      "52. cushman:2020-05-03\n",
      "53. ada:2020-05-03\n",
      "54. babbage:2020-05-03\n",
      "55. curie:2020-05-03\n",
      "56. davinci:2020-05-03\n",
      "57. if-davinci-v2\n",
      "58. if-curie-v2\n",
      "59. if-davinci:3.0.0\n",
      "60. davinci-if:3.0.0\n",
      "61. davinci-instruct-beta:2.0.0\n",
      "62. text-ada:001\n",
      "63. text-davinci:001\n",
      "64. text-curie:001\n",
      "65. text-babbage:001\n"
     ]
    }
   ],
   "source": [
    "# Print each model id\n",
    "for n, model in enumerate(models['data']):\n",
    "    print(str(n) + \". \" + model['root'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the available data for a particular model, we can subset it by number or use a 'for' loop or list comprehension to iterate through the models list until we find the model id that matches the one we want. For instance, to view \"gpt-4\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"created\": 1678604602,\n",
      "  \"id\": \"gpt-4\",\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\",\n",
      "  \"parent\": null,\n",
      "  \"permission\": [\n",
      "    {\n",
      "      \"allow_create_engine\": false,\n",
      "      \"allow_fine_tuning\": false,\n",
      "      \"allow_logprobs\": false,\n",
      "      \"allow_sampling\": false,\n",
      "      \"allow_search_indices\": false,\n",
      "      \"allow_view\": false,\n",
      "      \"created\": 1684465847,\n",
      "      \"group\": null,\n",
      "      \"id\": \"modelperm-HnvVZ1tf2jVawVaM1B3yjZnD\",\n",
      "      \"is_blocking\": false,\n",
      "      \"object\": \"model_permission\",\n",
      "      \"organization\": \"*\"\n",
      "    }\n",
      "  ],\n",
      "  \"root\": \"gpt-4\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Use a list comprehension to examine a particular model\n",
    "item = next((m for m in models['data'] if m['root'] == 'gpt-4'), None)\n",
    "print(item)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this model list doesn't contain a lot of the information we'd like to know, such as the cost to use each model, or its context limit. However, it does tell us whether we can fine-tune the model, which could be useful. We can use a list comprehension to get a list of all models that can be fine-tuned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cushman:2020-05-03', 'if-davinci:3.0.0', 'davinci-if:3.0.0', 'davinci-instruct-beta:2.0.0']\n"
     ]
    }
   ],
   "source": [
    "items = [m['root'] for m in models['data'] if m['permission'][0]['allow_fine_tuning']]\n",
    "print(items)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
